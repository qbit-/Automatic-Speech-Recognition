{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import sys\n",
    "import os\n",
    "if os.path.abspath('../') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('../'))\n",
    "if os.path.abspath('../../tt_keras') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('../../tt_keras'))\n",
    "\n",
    "if os.path.abspath('../../t3f') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('../../t3f'))\n",
    "\n",
    "import automatic_speech_recognition as asr\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import time\n",
    "from tensorflow import keras\n",
    "import horovod.tensorflow.keras as hvd\n",
    "from datetime import datetime\n",
    "\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# try:\n",
    "#       tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# except:\n",
    "#       pass\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Eval the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(model, optimizer=None):\n",
    "    alphabet = asr.text.Alphabet(lang='en')\n",
    "    features_extractor = asr.features.TfMFCC(\n",
    "        features_num=26,\n",
    "        winlen=0.032,\n",
    "        winstep=0.02,\n",
    "    )\n",
    "    \n",
    "    if optimizer is None:\n",
    "        optimizer = tf.optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    decoder = asr.decoder.RNNTGreedyDecoder(model, alphabet.blank_token)\n",
    "    pipeline = asr.pipeline.RNNTPipeline(\n",
    "        alphabet, features_extractor, model, optimizer, decoder\n",
    "    )\n",
    "    callbacks = []\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = asr.dataset.Audio.from_csv('./data/dev-clean-index.csv', batch_size=2, use_filesizes=True, librosa_read=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1554545cb668>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = asr.text.Alphabet(lang='en')\n",
    "model = asr.model.get_rnnt(26, \n",
    "                           num_layers_encoder=8, units_encoder=2048, projection_encoder=640, encoder_reduction_indexes=[1],\n",
    "                           units_prediction=2048, projection_prediction=640, num_layers_prediction=2, \n",
    "                           vocab_size=alphabet.size, \n",
    "                           blank_label=alphabet.blank_token)\n",
    "\n",
    "model.load_weights('./RNNT_experiments/rnnt_joint_nohidden_sum/rnnt_joint_nohidden_sum_train/rnnt_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output joint_network missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to joint_network.\n"
     ]
    }
   ],
   "source": [
    "pipeline = get_pipeline(model)\n",
    "pipeline.compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = './rnnt_joint_nohidden_sum_train'\n",
    "# callbacks = []\n",
    "# # schedule = tf.keras.experimental.CosineDecayRestarts(\n",
    "# #     1e-3, 10, t_mul=2.0, m_mul=1.0, alpha=0.0)\n",
    "# # callbacks.append(LearningRateScheduler(schedule))\n",
    "\n",
    "# callbacks.append(tf.keras.callbacks.ModelCheckpoint(\n",
    "#                     os.path.join(folder, 'rnnt_best.ckpt'),\n",
    "#                     monitor='loss', save_weights_only=True,\n",
    "#                     save_best_only=True))\n",
    "\n",
    "# pipeline.fit(dev_dataset, epochs=10, callbacks=callbacks)\n",
    "# pipeline.model.save_weights('./rnnt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer prediction_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "['the lady and the guitar certainly passed the night', 'the lady and the guitar certainly passed the night', 'the lady and the guitar certainly passed the night', 'the lady and the guitar certainly passed the night', 'the lady and the guitar certainly passed the night']\n",
      "['these intruders are very peculiar people remarked a man in the crowd', 'they seem very ignorant poor things said another in reply', 'the people must wait outside for there is no room for them in the palace', 'so they followed her through the low archway and in a room beyond very simply furnished sat a young girl engaged in darning a pair of pink stockings', 'she was a beautiful girl of about seventeen years of age not fat like all the rest of the pinkies but slender and well formed according to our own ideas of beauty']\n"
     ]
    }
   ],
   "source": [
    "decoder = asr.decoder.RNNTGreedyDecoder(model, alphabet.blank_token)\n",
    "\n",
    "eval_dataset = asr.dataset.Audio.from_csv('./data/dev-clean-index.csv', batch_size=5, use_filesizes=True, librosa_read=False)\n",
    "X, y = eval_dataset[3]\n",
    "print(pipeline.predict(X))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1554096845c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = asr.text.Alphabet(lang='en')\n",
    "model = asr.model.get_rnnt(26, \n",
    "                           num_layers_encoder=8, units_encoder=2048, projection_encoder=640, encoder_reduction_indexes=[1],\n",
    "                           units_prediction=2048, projection_prediction=640, num_layers_prediction=2, \n",
    "                           joint_additional_size=640, joint_aggregation_type='sum',\n",
    "                           vocab_size=alphabet.size, \n",
    "                           blank_label=alphabet.blank_token)\n",
    "\n",
    "model.load_weights('./RNNT_experiments/rnnt_joint_hidden_sum/rnnt_joint_nohidden_sum_train/rnnt_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output joint_network_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to joint_network_1.\n"
     ]
    }
   ],
   "source": [
    "pipeline = get_pipeline(model)\n",
    "pipeline.compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer prediction_network_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "['the', 'the', 'the', 'the', 'the']\n",
      "['these intruders are very peculiar people remarked a man in the crowd', 'they seem very ignorant poor things said another in reply', 'the people must wait outside for there is no room for them in the palace', 'so they followed her through the low archway and in a room beyond very simply furnished sat a young girl engaged in darning a pair of pink stockings', 'she was a beautiful girl of about seventeen years of age not fat like all the rest of the pinkies but slender and well formed according to our own ideas of beauty']\n"
     ]
    }
   ],
   "source": [
    "decoder = asr.decoder.RNNTGreedyDecoder(model, alphabet.blank_token)\n",
    "\n",
    "eval_dataset = asr.dataset.Audio.from_csv('./data/dev-clean-index.csv', batch_size=5, use_filesizes=True, librosa_read=False)\n",
    "X, y = eval_dataset[3]\n",
    "print(pipeline.predict(X))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1553f4fec048>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = asr.text.Alphabet(lang='en')\n",
    "model = asr.model.get_rnnt(26, \n",
    "                           num_layers_encoder=8, units_encoder=2048, projection_encoder=640, encoder_reduction_indexes=[1],\n",
    "                           units_prediction=2048, projection_prediction=640, num_layers_prediction=2, \n",
    "                           joint_aggregation_type='concat',\n",
    "                           vocab_size=alphabet.size, \n",
    "                           blank_label=alphabet.blank_token)\n",
    "model.load_weights('./RNNT_experiments/rnnt_joint_nohidden_concat/rnnt_joint_nohidden_sum_train/rnnt_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'the', 'the', 'the', 'the']\n",
      "['these intruders are very peculiar people remarked a man in the crowd', 'they seem very ignorant poor things said another in reply', 'the people must wait outside for there is no room for them in the palace', 'so they followed her through the low archway and in a room beyond very simply furnished sat a young girl engaged in darning a pair of pink stockings', 'she was a beautiful girl of about seventeen years of age not fat like all the rest of the pinkies but slender and well formed according to our own ideas of beauty']\n"
     ]
    }
   ],
   "source": [
    "decoder = asr.decoder.RNNTGreedyDecoder(model, alphabet.blank_token)\n",
    "\n",
    "eval_dataset = asr.dataset.Audio.from_csv('./data/dev-clean-index.csv', batch_size=5, use_filesizes=True, librosa_read=False)\n",
    "X, y = eval_dataset[3]\n",
    "print(pipeline.predict(X))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1551546b2208>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = asr.text.Alphabet(lang='en')\n",
    "model = asr.model.get_rnnt(26, \n",
    "                           num_layers_encoder=8, units_encoder=2048, projection_encoder=640, encoder_reduction_indexes=[1],\n",
    "                           units_prediction=2048, projection_prediction=640, num_layers_prediction=2, \n",
    "                            joint_additional_size=640, joint_aggregation_type='concat',\n",
    "                           vocab_size=alphabet.size, \n",
    "                           blank_label=alphabet.blank_token)\n",
    "model.load_weights('./RNNT_experiments/rnnt_joint_hidden_concat/rnnt_joint_nohidden_sum_train/rnnt_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'the', 'the', 'the', 'the']\n",
      "['these intruders are very peculiar people remarked a man in the crowd', 'they seem very ignorant poor things said another in reply', 'the people must wait outside for there is no room for them in the palace', 'so they followed her through the low archway and in a room beyond very simply furnished sat a young girl engaged in darning a pair of pink stockings', 'she was a beautiful girl of about seventeen years of age not fat like all the rest of the pinkies but slender and well formed according to our own ideas of beauty']\n"
     ]
    }
   ],
   "source": [
    "decoder = asr.decoder.RNNTGreedyDecoder(model, alphabet.blank_token)\n",
    "\n",
    "eval_dataset = asr.dataset.Audio.from_csv('./data/dev-clean-index.csv', batch_size=5, use_filesizes=True, librosa_read=False)\n",
    "X, y = eval_dataset[3]\n",
    "print(pipeline.predict(X))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sbatch_scripts(script_paths, environ_vars=None):\n",
    "    \"\"\"\n",
    "    Runs sbatch {script_name}.sh for every script in script_paths. \n",
    "    Before running changes working directory to script dir.\n",
    "    \"\"\"\n",
    "    # We will set variables using \"A=B C=D sbatch script.sh\" syntax\n",
    "    var_init_str = ' '.join([f'{name}={value}' for name, value in environ_vars.items()])\n",
    "    var_init_str += ' '\n",
    "    \n",
    "    for path in script_paths:\n",
    "        command_string = f\"cd {path.parent}; {var_init_str} sbatch ../../subm_python_small.sh train.py\"\n",
    "        print(os.popen(command_string).read())\n",
    "\n",
    "exp_names = [\n",
    "    'rnnt_joint_nohidden_sum',\n",
    "    'rnnt_joint_hidden_sum',\n",
    "    'rnnt_joint_nohidden_concat',\n",
    "    'rnnt_joint_hidden_concat'\n",
    "]\n",
    "script_paths = [Path(f'./RNNT_experiments/{name}/{name}.py') for name in exp_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 428194\n",
      "\n",
      "Submitted batch job 428195\n",
      "\n",
      "Submitted batch job 428196\n",
      "\n",
      "Submitted batch job 428197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_sbatch_scripts(\n",
    "    script_paths, \n",
    "    {\n",
    "        'PYTHONPATH': os.environ['PYTHONPATH']+':/trinity/home/g.leleitner/lab/Horovod/Automatic-Speech-Recognition:\\\n",
    "/trinity/home/g.leleitner/lab/Horovod/tt_keras:/trinity/home/g.leleitner/lab/Horovod/t3f:\\\n",
    "/trinity/home/g.leleitner/lab/Horovod/tf2-gradient-checkpointing'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model,\n",
    "#                 model_name,\n",
    "#                 dataset_idx, \n",
    "#                 val_dataset_idx=None, \n",
    "#                 batch_size=2, \n",
    "#                 epochs=25, \n",
    "#                 tensorboard=False, \n",
    "#                 restart_filename=None):\n",
    "#     model_dir = os.path.join(model_name + '_train')\n",
    "#     os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "#     if restart_filename:\n",
    "#         model.load_weights(restart_filename)\n",
    "#     dataset = asr.dataset.Audio.from_csv(dataset_idx, batch_size=batch_size, use_filesizes=True, librosa_read=False)\n",
    "#     dataset.sort_by_length()\n",
    "#     dataset.shuffle_indices()\n",
    "#     if val_dataset_idx:\n",
    "#         val_dataset = asr.dataset.Audio.from_csv(val_dataset_idx, batch_size=batch_size, use_filesizes=True, librosa_read=False)\n",
    "\n",
    "#     opt = tf.optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "#     opt = hvd.DistributedOptimizer(opt)\n",
    "    \n",
    "#     pipeline = get_pipeline(model, opt)\n",
    "#     callbacks = [\n",
    "#         hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "#         hvd.callbacks.MetricAverageCallback(),\n",
    "#     ]\n",
    "    \n",
    "#     if hvd.rank() == 0:\n",
    "#         prefix = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#         monitor_metric_name = 'loss' # if not val_dataset_idx else 'val_loss'  # val_loss is wrong and broken\n",
    "#         callbacks.append(\n",
    "#             keras.callbacks.ModelCheckpoint(\n",
    "#                 os.path.join(model_dir, prefix + '_best.ckpt'),\n",
    "#                 monitor=monitor_metric_name, save_weights_only=True,\n",
    "#                 save_best_only=True))\n",
    "#         if tensorboard:\n",
    "#             logdir = os.path.join(model_dir, 'tb', prefix)\n",
    "#             tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, profile_batch=1)\n",
    "#             callbacks.append(tensorboard_callback)\n",
    "#     pipeline.compile_model(experimental_run_tf_function=False)\n",
    "#     pipeline.fit(dataset, epochs=epochs, dev_dataset=val_dataset,\n",
    "#                         callbacks=callbacks,\n",
    "#                         verbose=1 if hvd.rank() == 0 else 0,\n",
    "#                         validation_steps=10)\n",
    "\n",
    "# alphabet = asr.text.Alphabet(lang='en')\n",
    "# model = asr.model.get_rnnt(26, \n",
    "#                            num_layers_encoder=8, units_encoder=2048, projection_encoder=640, encoder_reduction_indexes=[1],\n",
    "#                            units_prediction=2048, projection_prediction=640, num_layers_prediction=2, \n",
    "#                            vocab_size=alphabet.size, \n",
    "#                            blank_label=alphabet.blank_token)\n",
    "\n",
    "# hvd.init()\n",
    "# train_model(model, 'rnnt_joint_nohidden_sum', './data/dev-clean-index.csv', './data/dev-clean-index.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr_3.7_tf21",
   "language": "python",
   "name": "asr_3.7_tf21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
